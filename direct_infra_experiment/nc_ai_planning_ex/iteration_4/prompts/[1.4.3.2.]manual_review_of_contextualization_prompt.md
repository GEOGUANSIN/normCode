### Step 3.2: Manual Review of Contextualization

**Objective:** To meticulously validate the context mapping, ensuring every inference in the plan is linked to a set of precise, minimal, and sufficient context files, ready for the final script generation phase. This step is critical for refining the automated output and guaranteeing high-quality materialization.

**Procedure:**

1.  **Examine `3.2_context_manifest.json` for Correctness and Precision:**
    *   **No Raw Files**: The primary check is to confirm that **no inference maps directly to a `raw---*.md` guide**. All raw knowledge must be deconstructed into targeted `shared---*.md` or step-specific files. The presence of a `raw---` mapping indicates an incomplete contextualization.
    *   **Relevance Check**: For each inference (e.g., `"1.3.3.2.object| {step 2.1...}"`), review its list of mapped context files. Ask: "Is every file in this list strictly necessary for this specific step?" Remove any that are irrelevant.
    *   **Sufficiency Check**: Conversely, ask: "Is the provided context sufficient for this step to be executed without ambiguity?" As we saw with `step 2.2`, some steps may require additional context files (e.g., syntax guides) to be fully defined. Add any missing, relevant context files.

2.  **Examine the `context_store` for Quality:**
    *   **Review `shared---*.md` Files**: Open the shared context files. Verify that each one is focused on a single, coherent topic (e.g., `shared---normcode_core_syntax.md` should only contain syntax). If a file covers too many topics, it should be broken down further.
    *   **Review Step-Specific Files (`{index}---*.md`)**: Check any step-specific context files. Ensure they contain information that is genuinely unique to that step. If the content could apply to other steps, refactor it into a new shared file.

**Outcome:** A validated and refined context manifest where every inference is linked to the precise, necessary, and sufficient context it needs. This provides a solid and reliable foundation for the automated script generation in Phase 4.
---
# The NormCode AI Planning Pipeline

## Project Goal

The project goal is to bootstrap from a high-level natural language prompt into a structured and executable plan using a meta-algorithmic pipeline. This pipeline, itself powered by a NormCode plan, methodically transforms an instruction by:

1.  **Distilling** the user's intent into a clean instruction and registering all raw context.
2.  **Deconstructing** the instruction into a formal, hierarchical NormCode plan (`.ncd`).
3.  **Contextualizing** the plan by enriching each formal step with precise, granular context.
4.  **Materializing** the final plan into an executable script, ready for an orchestrator.

This creates a system that can understand, decompose, contextualize, and act upon complex instructions in a transparent and repeatable manner.

## Core Inputs

Each iteration of the pipeline begins with two primary markdown files that define the scope and methodology of the task:

-   **`prompts/0_original_prompt.md`**: This file contains the high-level goal that is the target of the decomposition process. It defines the "what" that the pipeline needs to accomplish.
-   **`_meta_pipeline_prompt.md`**: This file documents the methodology used to bootstrap the entire process. It defines the "how" the decomposition and planning will be executed.

For the purpose of this project, these two files are kept synchronized and are updated dynamically through manual modifications to reflect the most current practices and understanding of the pipeline itself.

## The Four-Phase Pipeline

The pipeline is divided into four distinct phases, each with a specific objective:

1.  **Phase 1: Confirmation of Instruction**: Transforms the initial, conversational user prompt into a set of clean, structured inputs (an `Instruction Block` and a `Context Manifest`). This phase includes an opportunity for manual review to ensure accuracy.

2.  **Phase 2: Deconstruction into NormCode Plan**: Translates the clean `Instruction Block` into a semi-formal NormCode Draft (`.ncd`). This draft represents the logical structure of the plan and is designed for human review.

3.  **Phase 3: Contextualization and Plan Formalization**: Enriches the plan with specific, relevant context. It converts the `.ncd` draft into a formal `.nc` file with unique identifiers (`flow_index`) for each step and distributes context from a `context_store` to each of those steps.

4.  **Phase 4: Materialization into an Executable Script**: Translates the final, formalized `.nc` plan and its context map into a runnable Python script, ready for execution by an `Orchestrator`.

This structured, phased approach ensures that a high-level, ambiguous instruction can be methodically transformed into a precise, executable, and context-aware plan.


---
# NormCode Guide - Core Syntax

This document covers the fundamental syntax of NormCode, a semi-formal language for constructing a **plan of inferences**.

## Core Syntax: Concepts and Inferences

The fundamental unit of a Normcode plan is the **inference**. An inference is defined by a functional concept and its associated value concepts.

-   **Functional Concept (`<=`)**: This is the cornerstone of an inference. It "pins down" the inference by defining its core logic, function, or operation. Crucially, the functional concept is responsible for **invoking an agent's sequence** (e.g., `quantifying`, `imperative`), which is the underlying engine that executes the inference's logic.

-   **Value Concept (`<-`)**: This concept provides the concrete data for the inference. It specifies the inputs, outputs, parameters, or results that the functional concept operates on or produces.

The entire plan is represented in a hierarchical, vertical format. An inference begins with a root concept, followed by an indented functional concept (`<=`) that defines the operation. The value concepts (`<-`) are then supplied at the same or a more deeply nested level.

A line in Normcode can also have optional annotations for clarity and control:

`_concept_definition_ | _annotation_ // _comment_`

-   **`_concept_definition_`**: The core functional (`<=`) or value (`<-`) statement.
-   **`_annotation_`**: Optional metadata following the `|` symbol. This can be a **flow index** (e.g., `1.1.2`), an intended **data reference**, or the name of the invoked **agent's sequence**.
-   **`// _comment_`**: Human-readable comments.

**Example Structure of an Inference:**
```Normcode
_concept_to_infer_ // The overall goal of this inference
    <= _functional_concept_defining_the_operation_ | 
    quantifying // This invokes the 'quantifying' agent's sequence
    <- _input_value_concept_1_ // This is an input for the 
    operation
    <- _input_value_concept_2_
```
