## Step 5.1: Automated Script Generation

**Objective**: Your task is to transform a formalized NormCode plan (`.nc`) and its associated context into a set of executable Python artifacts: `concept_repo.json`, `inference_repo.json`, and a main runner script (`.py`).

**Core Inputs**:
- The formalized NormCode plan (`.nc` file).
- The final Context Manifest (`.json` file).
- The `context_store` directory.

### Procedure

The generation process follows a structured procedure to translate the abstract NormCode plan into concrete, executable repository objects. This should be approached as a design-first process before implementation.

#### 0. Design the Repositories (Pre-computation step)
Before generating any JSON, first sketch out the repository design.
-   **Concept List**: Enumerate every concept from the `.nc` file. For each, decide if it is ground, final, or intermediate. Plan its `reference_data` and `reference_axis_names`.
-   **Inference List**: For each inference in the `.nc` file, design the corresponding `InferenceEntry`. Choose the `inference_sequence`, map all the concept connections, and, most importantly, design the full `working_interpretation` JSON object.

#### 1. Identify All Concepts and Operators from the NormCode Plan

First, perform a full parse of the `.nc` file to identify every unique concept. Each concept must be classified by its type and behavior.

-   **Semantical object concepts (`{...}`)**: e.g., `{normcode draft}`, `{functional concept}`.
-   **Semantical statement concepts (`<...>`**) e.g., `<current normcode draft is complete>`.
-   **Semantical relation concepts (`[...]`)**: e.g., `[all {normcode draft}]`.
-   **Syntactical operator concepts**: The operators that define the plan's logic, such as `*every(...)`, `&across(...)`, `$.(...)`, `$+(...)`, `@if`, `@if!`, `@after`.
-   **Functional concepts**: The imperative `::(...)` and judgement `:%(...)` blocks that represent actions or decisions.

#### 2. Generate `ConceptEntry` Objects

For each unique concept identified, create a corresponding `ConceptEntry` object. The attributes of this object are determined by the concept's role in the plan.

**2.1. Classify Concept Behavior**

-   **Final outputs**: These are the ultimate goals of the plan. Mark them with `is_final_concept=True`.
-   **Ground concepts**: These are the initial inputs, prompts, or fixed operators. Mark them with `is_ground_concept=True` and populate their `reference_data` and `reference_axis_names`. For nested data, use a nested list in `reference_data`.
-   **Intermediate concepts**: These are temporary variables or loop items that exist only during the run.
-   **Functional / operator concepts**: These represent the plan's syntax (e.g., `*every`, `$.`, `@if`, `::({})`). They are typically ground concepts (`is_ground_concept=True`).

**2.2. Map NormCode Types to `ConceptEntry` Attributes**

-   **Objects (`{...}`)**: `type` = `"{}"`. `axis_name` should describe the semantic axis (e.g., `"normcode draft"`).
-   **Statements (`<...>`**) `type` = `"<>"`. Typically have no `reference_data` unless they are ground-truth judgements.
-   **Relations (`[...]`)**: `type` = `"[]"`. `axis_name` should describe the collection (e.g., `"all unit place value of numbers"`).
-   **Operators and Functions**: The `type` attribute should encode the operator class (e.g., `"*every"`, `"$.`, `"::({})"`). The `concept_name` should be the full textual form of the operator from the `.nc` file.

#### 3. Generate `InferenceEntry` Objects

For each inference block in the `.nc` plan, create a corresponding `InferenceEntry` object. This object makes the plan's execution logic explicit for the orchestrator.

**3.1. Map Core Fields**

-   **`flow_info`**: Set `flow_info={'flow_index': '...'}` from the NormCode sequence label (e.g., `1.`, `1.1.2`).
-   **`inference_sequence`**: Map the role annotation from the `.nc` file (e.g., `quantifying`, `assigning`, `imperative`). This determines which agent sequence will execute the step.
-   **`concept_to_infer`**: The concept being defined on the left side of the inference.
-   **`function_concept`**: The operator on the right side of the `<=` in the NormCode.
-   **`value_concepts` and `context_concepts`**: The concepts listed under the `"<-"` lines in the NormCode block.

**3.2. Synthesize `working_interpretation`**

This is the most critical part of the translation. The `working_interpretation` JSON object encodes the implicit syntax of the NormCode into an explicit structure the orchestrator can understand. Below are templates for different inference sequences.

-   **For `quantifying` (`*every`) inferences**:
    -   **Purpose**: Describe a loop's structure.
    -   **Shape**:
        ```json
        {
            "syntax": {
                "marker": "every",
                "quantifier_index": 1,
                "LoopBaseConcept": "{number pair}",
                "CurrentLoopBaseConcept": "{number pair}*1",
                "group_base": "number pair",
                "InLoopConcept": { "{carry-over number}*1": 1 },
                "ConceptToInfer": ["{new number pair}"]
            }
        }
        ```

-   **For `grouping` (`&across`) inferences**:
    -   **Purpose**: Describe a grouping operation.
    -   **Shape**:
        ```json
        {
            "syntax": {
                "marker": "across",
                "by_axis_concepts": "{number pair}*1"
            }
        }
        ```

-   **For `assigning` (`$.` or `$`) inferences**:
    -   **Purpose**: Describe data movement or updates.
    -   **Shape**:
        ```json
        {
            "syntax": {
                "marker": ".", // or "+" for append
                "assign_source": "{remainder}",
                "assign_destination": "*every(...)"
            }
        }
        ```

-   **For `timing` (`@if`, `@if!`, `@after`) inferences**:
    -   **Purpose**: Describe conditional execution.
    -   **Shape**:
        ```json
        {
            "syntax": {
                "marker": "if", // or "if!" or "after"
                "condition": "<current normcode draft is complete>"
            }
        }
        ```

-   **For `imperative` or `judgement` inferences**:
    -   **Purpose**: Describe a call to a tool, LLM, or script.
    -   **Complex Shape (with value selectors)**: When an imperative needs to extract specific parts of a relation concept, use `value_selectors`:
        ```json
        {
            "is_relation_output": true,
            "with_thinking": true,
            "prompt_location": "name_of_prompt_file",
            "value_order": { ... },
            "value_selectors": {
              "relation_part_1": {
                  "source_concept": "[{concept to decomposed} and {remaining normtext}]",
                  "index": 0,
                  "key": "concept to decomposed"
              },
              "relation_part_2": {
                  "source_concept": "[{concept to decomposed} and {remaining normtext}]",
                  "index": 0,
                  "key": "remaining normtext"
              }
            }
        }
        ```
    -   The `value_order` map is crucial for binding the `value_concepts` to the positional placeholders (`{1}`, `{2}`) in the functional concept's text.

#### 4. Generate Repository Files

-   Serialize the complete list of `ConceptEntry` objects into `concept_repo.json`.
-   Serialize the complete list of `InferenceEntry` objects into `inference_repo.json`.

#### 5. Generate the Runner Script (`.py`)

Finally, generate a Python script that uses the repository files to execute the plan. The script should follow this template and include any necessary file system preparation (e.g., creating a `prompts/` directory if the plan requires it).

```python
from infra._orchest._repo import ConceptRepo, InferenceRepo
from infra._orchest._orchestrator import Orchestrator
from infra._agent._body import Body
import os
import json

def create_repositories_from_files():
    with open('concept_repo.json', 'r') as f:
        concept_data = json.load(f)
    concept_repo = ConceptRepo.from_json_list(concept_data)

    with open('inference_repo.json', 'r') as f:
        inference_data = json.load(f)
    inference_repo = InferenceRepo.from_json_list(inference_data, concept_repo)
    
    return concept_repo, inference_repo

if __name__ == "__main__":
    # 1. Build repositories from the generated JSON files
    concept_repo, inference_repo = create_repositories_from_files()

    # 2. Construct a Body for imperatives/judgements
    body = Body(llm_name="qwen-plus") # Or other appropriate configuration

    # 3. Construct and run the orchestrator
    orchestrator = Orchestrator(
        concept_repo=concept_repo,
        inference_repo=inference_repo,
        body=body,
        max_cycles=300,
    )
    final_concepts = orchestrator.run()

    # 4. Inspect and log final concepts
    for final_concept_entry in final_concepts:
        if final_concept_entry and final_concept_entry.concept.reference:
            ref_tensor = final_concept_entry.concept.reference.tensor
            print(f"Final concept '{final_concept_entry.concept_name}': {ref_tensor}")
        else:
            print(f"No reference found for final concept '{final_concept_entry.concept_name}'.")

```
