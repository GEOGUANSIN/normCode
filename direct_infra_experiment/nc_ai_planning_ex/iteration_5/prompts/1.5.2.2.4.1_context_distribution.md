# The NormCode AI Planning Pipeline

## Project Goal

The project goal is to bootstrap from a high-level natural language prompt into a structured and executable plan using a meta-algorithmic pipeline. This pipeline, itself powered by a NormCode plan, methodically transforms an instruction by:

1.  **Distilling** the user's intent into a clean instruction and registering all raw context.
2.  **Deconstructing** the instruction into a formal, hierarchical NormCode plan (`.ncd`).
3.  **Contextualizing** the plan by enriching each formal step with precise, granular context.
4.  **Materializing** the final plan into an executable script, ready for an orchestrator.

This creates a system that can understand, decompose, contextualize, and act upon complex instructions in a transparent and repeatable manner.

## Core Inputs

Each iteration of the pipeline begins with two primary markdown files that define the scope and methodology of the task:

-   **`prompts/0_original_prompt.md`**: This file contains the high-level goal that is the target of the decomposition process. It defines the "what" that the pipeline needs to accomplish.
-   **`_meta_pipeline_prompt.md`**: This file documents the methodology used to bootstrap the entire process. It defines the "how" the decomposition and planning will be executed.

For the purpose of this project, these two files are kept synchronized and are updated dynamically through manual modifications to reflect the most current practices and understanding of the pipeline itself.

## The Four-Phase Pipeline

The pipeline is divided into four distinct phases, each with a specific objective:

1.  **Phase 1: Confirmation of Instruction**: Transforms the initial, conversational user prompt into a set of clean, structured inputs (an `Instruction Block` and a `Context Manifest`). This phase includes an opportunity for manual review to ensure accuracy.

2.  **Phase 2: Deconstruction into NormCode Plan**: Translates the clean `Instruction Block` into a semi-formal NormCode Draft (`.ncd`). This draft represents the logical structure of the plan and is designed for human review.

3.  **Phase 3: Contextualization and Plan Formalization**: Enriches the plan with specific, relevant context. It converts the `.ncd` draft into a formal `.nc` file with unique identifiers (`flow_index`) for each step and distributes context from a `context_store` to each of those steps.

4.  **Phase 4: Materialization into an Executable Script**: Translates the final, formalized `.nc` plan and its context map into a runnable Python script, ready for execution by an `Orchestrator`.

This structured, phased approach ensures that a high-level, ambiguous instruction can be methodically transformed into a precise, executable, and context-aware plan.



---
### Step 3.2: Automated Context Distribution

With a formalized plan, the system can now accurately distribute context. This process feeds two artifacts to an LLM guided by a specialized meta-prompt:

1.  The formalized **NormCode (`.nc`)** file from Phase 2.
2.  The **Initial Context Manifest (`.json`)** and its associated `context_store` directory from Phase 1.

The LLM's task is to act as a context-aware analyst. It parses the raw documents (e.g., `raw---prompt.txt`, `raw---system_context.json`) in the `context_store` and, for each inference in the `.nc` plan, creates new, tailored context files. These are saved back to the `context_store` with specific naming conventions:

-   `{flow_index}---{description}.txt`: For contexts specific to a single inference.
-   `shared---{description}.txt`: For contexts used by multiple inferences.

The primary outputs are these newly generated context files and the updated `3.2_context_manifest.json` that maps inferences to them.

---

### Example Walkthrough

To illustrate, consider a user registration plan.

**1. Inputs:**

-   **Formalized Plan (`.nc` snippet):**
    ```normcode
    1.output|:<:(::(register a new user))
    1.1.grouping| &across[{1},{2},{3}]
    1.2.object| {step 1: check existence}<:{1}>
    1.2.1.assigning| $::.<username exists>
    1.2.2.judgement| ::<username exists?>
    1.2.2.1.object| {user name}
    1.3.object| {step 2: report error}<:{2}>
    1.3.1.assigning| $::.{error}
    1.3.2.imperative| ::(report error)
    1.3.2.1.timing| @if(<username exists?>)
    1.4.object| {step 3: create account}<:{3}>
    1.4.1.assigning| $::.{new user account}
    1.4.2.imperative| ::(create new user account)
    1.4.2.1.timing| @if!(<username exists?>)
    ```

-   **Initial `context_store`:**
    ```
    context_store/
    â”œâ”€â”€ raw---prompt.txt
    â””â”€â”€ raw---system_context.json
    ```

**2. LLM Analysis and Context Creation:**

The LLM processes each inference:

-   **For inference `1.1.1` (`::<username exists?>`):**
    -   It identifies the need for database details and the case-insensitivity requirement.
    -   It extracts "database type: PostgreSQL, user_table: 'users', username_column: 'username'" from `raw---system_context.json`.
    -   It extracts "username check should be case-insensitive" from `raw---prompt.txt`.
    -   It synthesizes this into a new file: `context_store/1.2.2---check_username_existence.txt`.

-   **Shared Context Identification:**
    -   The LLM notices that multiple steps will interact with the database.
    -   It creates a shared context file: `context_store/shared---database_connection.txt`, containing the PostgreSQL connection details. This avoids duplicating this information for every database-related step.

**3. Outputs:**

-   **Updated `context_store`:**
    ```
    context_store/
    â”œâ”€â”€ 1.2.2---check_username_existence.txt
    â”œâ”€â”€ raw---prompt.txt
    â”œâ”€â”€ raw---system_context.json
    â””â”€â”€ shared---database_connection.txt
    ```

-   **Updated Context Manifest (`3.2_context_manifest.json` snippet):**
    ```json
    {
      "context_mapping": {
        "1.2.2.object| ::<username exists?>": [
          "./context_store/1.2.2---check_username_existence.txt",
          "./context_store/shared---database_connection.txt"
        ],
        // ... other mappings
      }
    }
    ```

---

