\section{The Compiler Ecosystem}

The NormCode compiler transforms human-authored plans into executable artifacts through a multi-stage pipeline. Each stage progressively adds rigor while preserving opportunities for human review.

\subsection{The Five-Phase Pipeline (Abstract)}

The current implementation follows a five-phase pipeline that transforms a natural language instruction into an executable NormCode plan. Notably, \textbf{this pipeline is itself implemented as a NormCode plan}---a form of self-hosting that validates the framework's expressive power.

\begin{table}[t!]
\centering
\begin{tabular}{llll}
\toprule
\textbf{Phase} & \textbf{Input} & \textbf{Output} & \textbf{Purpose} \\ 
\midrule
\textbf{1. Confirmation} & Raw prompt & Instruction Block + & Distill intent; \\ 
& & Context Manifest & register context \\ 
\textbf{2. Deconstruction} & Instruction Block & \texttt{.ncd} Draft + & Parse into \\ 
& & \texttt{.ncn} Translation & hierarchical inferences \\ 
\textbf{3. Formalization} & \texttt{.ncd} Draft & Serialized + & Add flow indices, \\ 
& & Redirected \texttt{.ncd} & explicit data flow \\ 
\textbf{4. Contextualization} & Formalized \texttt{.ncd} & Prompt files + & Distribute context \\ 
& + Context & Context Manifest & to each step \\ 
\textbf{5. Materialization} & Final \texttt{.ncd} & JSON Repos + & Generate \\ 
& + Context & Runner Script & executable artifacts \\ 
\bottomrule
\end{tabular}
\caption{The Five-Phase NormCode Compiler Pipeline.}
\label{tab:compiler_phases}
\end{table*}

Each phase includes an opportunity for \textbf{manual review}, enabling human intervention before the next stage proceeds. This supports the Progressive Formalization philosophy: the plan tightens incrementally, not all at once.

\subsection{Deconstruction: Natural Language to Structure}

The deconstruction phase is the most LLM-intensive. It uses a recursive decomposition algorithm: (1) \textbf{Initialize}: Wrap the entire instruction as a top-level concept; (2) \textbf{Loop}: Identify un-decomposed concepts, formulate questions, classify types, construct concepts, and distribute source text; and (3) \textbf{Terminate}: When no annotations remain.

This process is guided by a taxonomy of question types that map to specific NormCode operators (e.g., ``Methodology Declaration'' $\to$ \texttt{@by}, ``Conditional Dependency'' $\to$ \texttt{@if}).

\subsection{Formalization: Adding Rigor}

Once the structure is established, formalization adds precision: \textbf{Serialization} reframes steps as output-effect relationships; \textbf{Redirection} links abstract references to concrete implementations; and \textbf{Flow Index Generation} assigns unique addresses. The result is a \texttt{.ncd} file with explicit inputs, outputs, and identity.

\subsection{Activation Compilation: .ncd $\to$ JSON Repositories}

The final compilation stage transforms the formalized \texttt{.ncd} into executable JSON repositories: the \textbf{Concept Repository} (fields: `concept\_name`, `type`, `reference\_data`, `reference\_axis\_names`) and the \textbf{Inference Repository} (fields: `flow\_index`, `inference\_sequence`, and the critical `working\_interpretation` encoding implicit syntax).

\subsection{Translation: .ncd $\to$ .ncn}

For human verification, the system can generate a \textbf{Natural Language NormCode} (\texttt{.ncn}) file. This strips the formal markers and presents the plan as readable prose:

\textbf{\texttt{.ncd} input:}
\begin{verbatim}
<- {Phase 1: Confirmation of Instruction}
    <= &across
    <- {step 1.1: Automated Instruction Distillation}
    <- {step 1.2: Automated Context Registration}
\end{verbatim}

\textbf{\texttt{.ncn} output:}
\begin{verbatim}
The first phase is Confirmation of Instruction.
    <= This phase is specified as a series of steps.
    <- The first step is Automated Instruction Distillation.
    <- The second step is Automated Context Registration.
\end{verbatim}

This enables domain experts (who may not understand the formal syntax) to verify the plan's logic before execution.

\subsection{Current Status and Limitations}

The compiler ecosystem is functional but still maturing: it is **Working** (validated on the self-hosted pipeline), **In Progress** (optimizing NL deconstruction prompts), and targeting **Future Work** in automated prompt generation and robust error recovery.

